{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking and selecting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll exemplify some of scikit-learn's ranking functions used to score the importance of features. We'll reuse the running example, the Adult dataset that we used in the first exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "train_data = pd.read_csv('adult_train.csv')\n",
    "n_cols = len(train_data.columns)\n",
    "Xtrain_dicts = train_data.iloc[:, :n_cols-1].to_dict('records')\n",
    "Ytrain = train_data.iloc[:, n_cols-1]\n",
    "\n",
    "test_data = pd.read_csv('adult_test.csv')\n",
    "Xtest_dicts = test_data.iloc[:, :n_cols-1].to_dict('records')\n",
    "Ytest = test_data.iloc[:, n_cols-1]\n",
    "\n",
    "dv = DictVectorizer()\n",
    "dv.fit(Xtrain_dicts)\n",
    "\n",
    "X_vec = dv.transform(Xtrain_dicts)\n",
    "\n",
    "dv.get_feature_names_out()\n",
    "\n",
    "#feature_scores = mutual_info_classif(X_vec, Ytrain)\n",
    "\n",
    "#for score, fname in sorted(zip(feature_scores, dv.get_feature_names_out()), reverse=True)[:10]:\n",
    "#    print(fname, score)\n",
    "    \n",
    "#from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "#pipeline = make_pipeline(\n",
    "#        DictVectorizer(),\n",
    "#        SelectKBest(mutual_info_classif, k=100), # or SelectPercentile(...)\n",
    "#        DecisionTreeClassifier()\n",
    "#)\n",
    "#pipeline.fit(Xtrain_dicts, Ytrain)\n",
    "#accuracy_score(Ytest, pipeline.predict(Xtest_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('adult_train.csv')\n",
    "\n",
    "n_cols = len(train_data.columns)\n",
    "Xtrain_dicts = train_data.iloc[:, :n_cols-1].to_dict('records')\n",
    "Ytrain = train_data.iloc[:, n_cols-1]\n",
    "\n",
    "test_data = pd.read_csv('adult_test.csv')\n",
    "Xtest_dicts = test_data.iloc[:, :n_cols-1].to_dict('records')\n",
    "Ytest = test_data.iloc[:, n_cols-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might recall, the instances in this dataset consist of several features describing each individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_dicts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first convert the training set into numerical vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer()\n",
    "dv.fit(Xtrain_dicts)\n",
    "\n",
    "X_vec = dv.transform(Xtrain_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first scoring function we'll investigate is called the [mutual information](https://en.wikipedia.org/wiki/Mutual_information). [Here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html) is the description from scikit-learn about how this scoring function works.\n",
    "\n",
    "(To see the formula used to compute the mutual information score, see the [description](https://nlp.stanford.edu/IR-book/html/htmledition/mutual-information-1.html) in the book *Introduction to Information Retrieval* by Manning and Sch√ºtze.)\n",
    "\n",
    "We apply the scoring function to all the features, and we then print the top 10 high-scoring features. Please refer back to the perceptron example in the previous lecture for an explanation about the step where we sort the features by importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "feature_scores = mutual_info_classif(X_vec, Ytrain)\n",
    "\n",
    "for score, fname in sorted(zip(feature_scores, dv.get_feature_names_out()), reverse=True)[:10]:\n",
    "    print(fname, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second scoring function uses the so-called $F$-statistic in an [ANOVA test](https://en.wikipedia.org/wiki/Analysis_of_variance).\n",
    "\n",
    "As you can see, there is an overlap between the top-10 list produced by this scorer and the previous list, but they are not identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "feature_scores = f_classif(X_vec, Ytrain)[0]\n",
    "\n",
    "for score, fname in sorted(zip(feature_scores, dv.get_feature_names_out()), reverse=True)[:10]:\n",
    "    print(fname, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another feature scoring function. It is based on the well-known [$\\chi^2$ statistical test](https://en.wikipedia.org/wiki/Chi-squared_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "feature_scores = chi2(X_vec, Ytrain)[0]\n",
    "\n",
    "for score, fname in sorted(zip(feature_scores, dv.get_feature_names_out()), reverse=True)[:10]:\n",
    "    print(fname, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice when we'd like to use feature selection in scikit-learn, we just plug a selector into our pipeline. `SelectKBest` and `SelectPercentile` are the most common selectors. They use a feature scoring function (such as the ones above) to rank the features; by default, the `f_classif` scoring function is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "        DictVectorizer(),\n",
    "        SelectKBest(k=100), # or SelectPercentile(...)\n",
    "        DecisionTreeClassifier()\n",
    ")\n",
    "pipeline.fit(Xtrain_dicts, Ytrain)\n",
    "accuracy_score(Ytest, pipeline.predict(Xtest_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
