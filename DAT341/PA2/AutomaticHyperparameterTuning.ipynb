{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to use scikit-learn's procedures for automatically tuning the values of hyperparameters. Hyperparameters are inputs to learning algorithms that control their behavior.\n",
    "\n",
    "We first read the Adult dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('adult_train.csv')\n",
    "\n",
    "n_cols = len(train_data.columns)\n",
    "Xtrain = train_data.iloc[:, :n_cols-1].to_dict('records')\n",
    "Ytrain = train_data.iloc[:, n_cols-1]\n",
    "\n",
    "test_data = pd.read_csv('adult_test.csv')\n",
    "Xtest = test_data.iloc[:, :n_cols-1].to_dict('records')\n",
    "Ytest = test_data.iloc[:, n_cols-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `Pipeline` that handles all the preprocessing steps, and we then apply this preprocessing pipeline to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "preprocessing_pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    StandardScaler(with_mean=False),\n",
    "    SelectKBest(k=100),\n",
    ")\n",
    "\n",
    "preprocessing_pipeline.fit(Xtrain, Ytrain)\n",
    "X_vec = preprocessing_pipeline.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now carry out a grid search for the best hyperparameters for a `LogisticRegression` classifier.\n",
    "\n",
    "We'll tune the hyperparameters `C` and `penalty`. See [scikit-learn's documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) of the LogisticRegression classifier for details about these hyperparameters.\n",
    "\n",
    "For the grid search, we define lists of the values of each hyperparameter that we want to explore. The grid search procedure (which we run by calling `fit`) will then try out all combinations of values of each hyperparameter.\n",
    "\n",
    "The `GridSearchCV` will run a separate cross-validation for each combination of hyperparameter values, and select the values that gave the highest classification accuracy in the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "gridsearch = GridSearchCV(clf, param_grid)\n",
    "\n",
    "gridsearch.fit(X_vec, Ytrain);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After carrying out the grid search, we can inspect the hyperparameter values that led to the best results in the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative to the grid search, we'll also take a look at a random search. It has been claimed that this procedure finds better parameter values in a fewer number of experiments ([Bergstra and Bengio, 2012](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)).\n",
    "\n",
    "We could specify the parameter values to explore, just as for the grid search. However, in order to take advantage of the random search, it can be better to define a *distribution* for the continuous-value hyperparameters, such as `C` in the case of logistic regression. In this case, we'll use an [exponential distribution](https://docs.scipy.org/doc/scipy-0.19.1/reference/generated/scipy.stats.expon.html) for `C`. The `penalty` hyperparameter will still be a discrete choice.\n",
    "\n",
    "To find a good set of hyperparameter values, we should run many experiments. This can take a bit of time. I've set the number of iterations to 5 here, but in a real-world setting this number would probably be much higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import expon\n",
    "\n",
    "C_distr = expon(scale=2)\n",
    "param_grid_random = {'C': C_distr, 'penalty': ['l1', 'l2']}\n",
    "\n",
    "randomsearch = RandomizedSearchCV(clf, param_grid_random, n_iter=5)\n",
    "\n",
    "randomsearch.fit(X_vec, Ytrain);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can inspect the best hyperparameter values after running the selection procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train a classifier that uses the hyperparameter values found by the search procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C = randomsearch.best_params_['C']\n",
    "best_penalty = randomsearch.best_params_['penalty']\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    StandardScaler(with_mean=False),\n",
    "    SelectKBest(k=100),\n",
    "    LogisticRegression(C=best_C, penalty=best_penalty, solver='liblinear')\n",
    ")\n",
    "\n",
    "pipeline.fit(Xtrain, Ytrain)\n",
    "accuracy_score(Ytest, pipeline.predict(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
